Exercise 01.
RESP:
Cálculo do valor da Entropia do objetivo y para todo conjunto de treinamento:
 Y = 1 (classe positiva); Y = 0 (classe negativa)
Então:   H(y)=-[2/5  log_2⁡〖(2/5)+(1-2/5).log_2 (1-2/5)〗 ]=- (-0,523-0,442)=-0,965
	  H(y)=- 0,965
Com isso, encontra-se o nó raiz: Ganho de Informação
■(&&OUT@&&P@■(A1@■(@))&■(1@■(0@))&■(2@■(0@)))    ■(Y&@N&@■(2@■(1@))&■(4@■(1@5)))             ■(&&OUT@&&P@■(A2@■(@))&■(1@■(0@))&■(2@■(0@)))    ■(Y&@N&@■(1@■(2@))&■(3@■(2@5)))           ■(&&OUT@&&P@■(A3@■(@))&■(1@■(0@))&■(1@■(1@)))    ■(Y&@N&@■(1@■(2@))&■(2@■(3@5)))

Gain (A1)=0,965- [4/5.H(2/4)+ 1/5.H(0/1)]
H (2/4)=- [2/4  log_2⁡〖(2/4)+(1-2/4).log_2 (1-2/4)〗 ]= - (- 0.5-0.5)=1
H (0/1)=- [0/1  log_2⁡〖(0/1)+(1-0/1).log_2 (1-0/1)〗 ]= 0
Gain (A1)=0,965- [4/5.1+ 1/5.0]=0,165

Gain (A2)=0,965- [3/5.H(2/3)+ 2/5.H(0/2)]
H (2/3)=- [2/3  log_2⁡〖(2/3)+(1-2/3).log_2 (1-2/3)〗 ]= -(- 0,39-0,528)=0,918
H (0/2)= 0
Gain (A2)=0,965- [3/5.0,918+ 2/5.0]= -0,4142

Gain (A3)=0,965- [2/5.H(1/2)+ 3/5.H(1/3)]
H (1/2)=- [1/2  log_2⁡〖(1/2)+(1-1/2).log_2 (1-1/2)〗 ]= -(- 0,5-0,5)=1
H (1/3)= - [1/3  log_2⁡〖(1/3)+(1-1/3).log_2 (1-1/3)〗 ]= - (- 0,528 - 0,39)=0,918
Gain (A3)=0,965- [2/5.1+ 3/5.0,918]= 0,0142
A2 = 1: Analisando os resultados acima onde o ganho de informação é maximizado com o atributo A2, sendo assim opta-se pela escolha deste parâmetro como nó raiz da árvore de decisão.

■(A2=1&&OUT@&&P@■(A1@■(@))&■(1@■(0@))&■(2@■(0@)))    ■(Y&@N&@■(0@■(1@))&■(2@■(1@3)))             ■(A2=1&&OUT@&&P@■(A3@■(@))&■(1@■(0@))&■(1@■(1@)))    ■(Y&@N&@■(0@■(1@))&■(1@■(2@3)))         
Para A2 = 0 os valores dos atributos não contribuem, onde a classe predominante é a negativa com y = 0, sendo assim tem-se a folha deste ramo.
Gain (A1)=0,965- [⏟(2/3.H(2/2) )┬0+ ⏟(1/3.H(0/1) )┬0 ]= 0,965
Gain (A3)=0,965- [⏟(1/3.H(1/1) )┬0+ 2/3.H(1/2)]= 0,965    ؞     H (1/2)= 1
Gain (A3)=0,965- [2/3.1]= 0,2983

De acordo com os resultados acima, o atributo A1 resulta na maximização do ganho de informação quando A2 = 1. Desta forma o atributo A1 será o segundo nível da árvore de decisão em um dos ramos de A2. Abaixo segue o diagrama da árvore de decisão final.

 

Exercise 02.
RESP:
Cálculo do valor da Entropia do objetivo y para todo conjunto de treinamento:
 Y = 1 (classe positiva); Y = 0 (classe negativa)
Então:   H(y)=-[2/4  log_2⁡〖(2/4)+(1-2/4).log_2 (1-2/4)〗 ]=- (-0,5-0,5)= 1

Nó raiz da árvore de decisão:

■(&&OUT@&&P@■(X1@■(@))&■(1@■(0@))&■(1@■(1@)))    ■(Y&@N&@■(1@■(1@))&■(2@■(2@4)))             ■(&&OUT@&&P@■(X2@■(@))&■(1@■(0@))&■(1@■(1@)))    ■(Y&@N&@■(1@■(1@))&■(2@■(2@4)))

Gain (X1)=1- [2/4.⏟(H(1/2) )┬1+ 2/4.⏟(H(1/2) )┬1 ]=1- [2/4+ 2/4]=0
Gain (X2)= Gain (X1)=0 
Em resumo, dado os ganhos de informação serem iguais, então ambos X1 e X2 podem ser adotados como raiz da árvore de decisão (XOR). Neste caso, X1 será a raiz da árvore abaixo:
 



